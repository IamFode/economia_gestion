---
title: "master"
author: "Christian Limbert Paredes Aguilera"
date: "2022-12-21"
output: pdf_document
---



# 7.1 Polinomiales

## 7.1.1 Función de coste

La función de coste total, está dada por,

$$TC=\alpha_1+\alpha_2Q+\alpha_3 Q^2 + \alpha_4 Q^3 + e \qquad \qquad (7.2)$$

El coste $TC$ depende de la producción $Q$, $Q^2$ y $Q^3$

Si $7.2$ lo dividimos por la producción, nos da el costo medio. Es decir,

$$AC=\beta_1+\beta_2 Q + \beta_3 Q^2 + e\qquad \qquad (7.1)$$

Si realizamos la derivada de la producción en relación del costo medio, se tiene

$$\dfrac{\partial AC}{\partial Q}=\beta_2+2\beta_3 Q \qquad \qquad (7.3)$$

Que significa los cambios de costos medios cuando aumentamos en una unidad la producción.

Y el coste marginal está dado por

$$\dfrac{\partial TC}{\partial Q}=\alpha_2+2\alpha_3Q+3\alpha_4Q^2\qquad \qquad (7.4)$$

Que significa, como varia el coste total cuando varía en una unidad la pruducción.


La teoría de dualidad nos dice que toda producción tiene su coste. Es decir, podemos deducir el comportamiento de la producción a partir del comportamiento del coste.


## 7.1.2. Ecuación de los salarios

El salario esta dado por:

$$Wage = \beta_1 + \beta_2 EDUC + \beta_3 EXPER + \beta_4 EXPER^2 + e \qquad \qquad (7.5)$$

Si calculamos el efecto marginal de un año más de experiencia, tenemos

$$\dfrac{\partial E(WAGE)}{\partial EXPER}=\beta_3 + 2\beta_4 EXPER \qquad \qquad (7.6)$$


### Regresión de salarios

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
library(hexView)
salario = readEViews("../data/Suposto 1.3 Modelos salarios.3Edition.wf1")
salarios = lm(WAGE~EDUC+EXPER+I(EXPER^2),data=salario)
summary(salarios)
```

# 7.2 Variables Dummy

Se utiliza para variables cualitativas.

Queremos ver los precios de cada departamento. Donde SQFT es la superficie de la vivienda el cual explica los precios de un departamento.

$$PRICE = \beta_1 + \beta_2 SQFT + e\qquad \qquad (7.7)$$

Pero este modelo no explica del todo bien. Por lo que colocamos una variable dummy para el modelo (7.7)

$$D=\left\{\begin{array}{cl}
    1& \mbox{Si la vecindad es deseable}\\
    0& \mbox{Si la vecindad no es deseable}
\end{array}\right.$$

De donde,

$$PRICE = \beta_1+\delta D + \beta_2 SQFT + e\qquad \qquad (7.9)$$

Por lo que,

$$E(PRICE)=\left\{\begin{array}{ll}
  (\beta_1+\delta) + \beta_2 SQFT & \mbox{cuando } D=1\\
  \beta_1 + \beta_2 SQFT & \mbox{cuando } D=0
\end{array}\right.\qquad \qquad (7.10)$$

Debemos cuidar de las trampas ficticias. Por ejemplo, si incluimos una variable inversa a $D$:

$$
LD=
\left\{
  \begin{array}{cl}
    1 & \mbox{Si el vecindario es no deseable.}\\
    0 & \mbox{Si el vecindario es deseable.}
  \end{array}
\right.
$$

Por lo que,

$$PRICE = \beta_1+\gamma LD + \beta_2 SQFT + e$$
$$PRICE = \beta_1+\delta D + \gamma LD + \beta_2 SQFT + e$$

El modelo sólo estimara si metemos $\beta_1$ con una variable dummy o dos variables dummys sin $\beta_1$.

## 7.2.2. Dammy multiplicativa

Sea $SQFT$ la superfice, entonces

$$PRICE = \beta_1+ \beta_2SQFT + \gamma(SQFT\cdot D) + e\qquad \qquad (7.11)$$

Donde se dice que tenemos un efecto indirecto vía superficie.

$$E(PRICE) =\beta_1+\beta_2 SQFT+\gamma(SQFT\cdot D) 
=\left\{\begin{array}{rr}
  \beta_1+(\beta_2+\gamma)SQFT & D=1\\
  \beta_1+\beta_2SQFT & D=0
\end{array}\right.
$$

$$\dfrac{\partial E(PRICE)}{\partial SQFT}=
\left\{\begin{array}{rr}
  \beta_2-\gamma & D=1\\
  \beta_2 & D=0
\end{array}\right.
$$

Las Dummys aditivas cambian la ordenada del origen y las dummys multiplicativas cambian la pendiente.


```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
```

Podemos tomar el efecto aditivo y multiplicativo

$$PRICE=\beta_1 + \delta D+\beta_2SQFT + \gamma(SQFT\cdot D)+e\qquad \qquad (7.12).$$

$$E(PRICE) = \left\{\begin{array}{rr}
  (\beta_1+\delta)+(\beta_2+\gamma)SQFT & D=1\\
  \beta_1+\beta_2SQFT & D=0
\end{array}\right.$$


## 7.2.3 Un Ejemplo: El efecto de la universidad en precios de casas

$$PRICE = \beta_1 + \delta UTOWN + \beta_2 SQFT + \gamma(SQFT\cdot UTOWN)+\beta_3 AGE + \delta_2 POOL + \delta_3FPLACE+e\qquad \qquad (7.13)$$

$$
  \begin{array}{rcl}
    UTOWN &\Rightarrow& \mbox{Ubicación}\\
    POOL &\Rightarrow& \mbox{tiene piscina}\\
    FPLACE &\Rightarrow& \mbox{tiene chimenea}
  \end{array}
$$


```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
library(hexView)
precios = readEViews("../data/Supuesto 1.4 modelos precios. 3edition.wf1")
salarios = lm(PRICE~UTOWN+SQFT+I(SQFT*UTOWN)+AGE+POOL+FPLACE,data=precios)
names(salarios$coefficients)= c("Beta 1","UTOWN","SQFT","SQFT*UTOWN","AGE","POOL","FPLACE")
summary(salarios)
```

Luego, sustituimos en el modelo igualando UTOWN a 1 para saber las viviendas que están próximas a la universidad:

$$
  \begin{array}{rcl}
    PRICE &=& 24.5 + 27.453 \cdot 1 + 7.6122 \cdot SQFT + 1.2994(SQFT\cdot 1)-0.1901 \cdot AGE\\
      &+& 4.3772 \cdot POOL + 1.6492 \cdot FPLACE\\
      &=& 51.953 + 8.9116\cdot SQFT - 0.1901 \cdot AGE + 4.3772 \cdot POOL + 1.6492 \cdot FPLACE
\end{array}
$$

Interpretaciones:

- EL efecto directo de que una casa este cerca de la universidad será $27.453$
- EL efecto indirecto de que una casa este cerca de la universidad será $89.116$
- Efecto de la depreciación de los años $190\cdot 1000$ el cual se deprecia 190 dolares por año.
- El efecto de tener piscina o no, incrementa el valor de las viviendas en $4.3772\cdot 1000 = 4377.2$ dolares.
- El efecto de tener chimenea o no, incrementa le valor de las viviendas en $1.6492\cdot 1643.2$ dolares.

La variable dependiente esta en miles por lo que multiplicamos por 1000.


Y si sustituimos UTOWN por $0$, entonces las viviendas que estén lejanas a la universidad estarán dada por:

$$PRICE = 24.5 +  7.6122 \cdot SQFT-0.1901 \cdot AGE + 4.3772 \cdot POOL + 1.6492 \cdot FPLACE$$

Interpretaciones:

- EL efecto indirecto de que una casa este lejos de la universidad será $76.122$



```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
#library
library(hexView)
library(aod)
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
# data
salario = readEViews("../data/Suposto 1.3 Modelos salarios.3Edition.wf1")
```



# 7.3 Aplicando variables dummy

## 7.3.1. Interacción sobre factores cualitativos

Analizaremos dos factores, como lo es la raza y el sexo.

$$wage = \beta_1+\beta_2 educ + \delta_1 BLACK + \delta_2 FEMALE + \gamma(BLACK\cdot FEMALE)+e\qquad (7.14)$$

Por lo que

$$
E(WAGE) = 
  \left\{
    \begin{array}{rl}
      \beta_1+\beta_2 EDUC & \mbox{Si el hombres es blanco}.\\
      (\beta_1+\delta_1)+\beta_2 EDUC&\mbox{Si el hombre es negro.}\\
      (\beta_1+\delta_2)+\beta_2 EDUC&\mbox{Si la mujer es blanca}.\\
      (\beta_1+\delta_1+\delta_2+\gamma)+\beta_2\cdot EDUC&\mbox{Si la mujer es negra.}\\
    \end{array}
  \right.
$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
salariosU = lm(WAGE~EDUC+BLACK+FEMALE+I(BLACK*FEMALE),data=salario)
summary(salariosU)
```

Ahora, Realizaremos la hipótesis de conjunta de los parámetros que acompañan a raza y sexo. Para ello, observamos la ecuación dada:

$$
H_0=\delta_1=\delta_2=\gamma=0
$$
Se sigue que:

$$WAGE=\beta_1+\beta_2EDUC+e$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
salariosR = lm(WAGE~EDUC,data=salario)
summary(salariosR)
```

Este modelo lo llamamos restringido. Luego, comparamos (7.14). Si la diferencia de los R-cuadrado de los modelos es significativa, entonces los parametros raza y sexo aportan al modelo.

#### Interpretación

- Los hombres negros ganan 1.83 dolares por hora  menos que los hombres blancos.
- Las mujeres blancas ganan 2.55 dolares menos que los hombres blancos.
- La situación mas desfavorable será: $\beta_1+\delta_1+\beta_2=-1.83-2.55+0.58=3.8$ dolares que un hombre blanco.

Ahora, este última interpretación es significativo?

Para ello aplicamos el test de WALD con la hipótesis $H_0$ que nos planteamos

$$F=\dfrac{\dfrac{SSE_R-SSE_U}{J}}{\dfrac{SSE_U}{(N-K)}} = \dfrac{\dfrac{31092.99-29307.71}{3}}{\dfrac{29307.71}{995}}= `r ((sum(salariosR$residuals^2)-sum(salariosU$residuals^2))/3)/(sum(salariosU$residuals^2)/salariosU$df.residual)`$$

Donde
$$
  \begin{array}{rcl}
    SSE_R &=& \mbox{Suma de cuadrado de los errores del modelo restringido.}\\
    SSE_U &=& \mbox{Suma de cuadrado de los errores del modelo sin restricción.}\\
    J &=& \mbox{El número de restricciones}\\
    N &=& \mbox{Número de observaciones}\\
    K &=& \mbox{Parámetros a estimar del modelo sin restricciones}
  \end{array}
$$

Al valor critico de $1\%$ se tiene

$$F(0.99,3,995)=`r qf(0.99,3,995)`$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wald=wald.test(Sigma=vcov(salariosU),coef(salariosU),Terms = 3:5)
wald
```

Si $F$ es mayor al valor crítico, entonces se rechaza la hipótesis nula. Lo que significa que el efecto conjunto de raza y sexo es significativa.


Para Raza viene dada por
```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wald1=wald.test(Sigma=vcov(salariosU),coef(salariosU),Terms = 3)
wald1
```



## 7.3.2 Factores cualitativos y varias categorias

Sea,

$$WAGE=\beta_1+\beta_2EDUC+\delta_1SOUTH+\delta_2MIDWEST+\delta_3WEST+e$$
Donde la categoría noroeste es la categoría de referencia, es decir,

$$
E(WAGE)=
  \left\{
    \begin{array}{rl}
      (\beta_1+\delta_3)+\beta_2EDUC & WEST\\
      (\beta_1+\delta_2)+\beta_2EDUC & MIDWEST\\
      (\beta_1+\delta_1)+\beta_2 EDUC & SOUTH\\
      \beta_1+\beta_2EDUC & NORTHEAST
    \end{array}
  \right.
$$

A la tabla 7.14 añadimos el efecto regional

$$wage = \beta_1+\beta_2 educ + \delta_1 BLACK + \delta_2 FEMALE + \gamma(BLACK\cdot FEMALE)+ \delta_3SOUTH+\delta_4MIDWEST+\delta_5WEST + e$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wage = lm(WAGE~EDUC+BLACK+FEMALE+I(BLACK*FEMALE)+SOUTH+MIDWEST+WEST,data=salario)
summary(wage)
```

Vemos que R2 mejoró pero muy poco.

#### Test de Wald

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wald2=wald.test(vcov(wage),coef(wage),Terms = 6:8)
wald2
```
No es significativo al 1 ni al 5 por ciento pero si lo es al 10 por ciento.

El término regional no es del todo representativo en el modelo.




```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
#library
library(hexView)
library(aod)
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
# data
salario = readEViews("../data/Suposto 1.3 Modelos salarios.3Edition.wf1")
gasto = readEViews("../data/Suposto 1.5 Modelos pizza. 3Edition.wf1")
```

## 7.3.3 Testeando dos regresiones equivalentes

$$
  \begin{array}{rcl}
    WAGE &=& \beta_1 + \beta_2EDUC + \delta_1BLACK + \delta_2 FEMALE + \gamma(BLACK\cdot FEMALE)+\theta_1SOUTH\\
    &+&\theta_2(EDUC\cdot SOUTH)+\theta_3(BLACK\cdot SOUTH) +\theta_4(FEMALE\cdot SOUTH)\\
    &+&\theta_5(BLACK\cdot FEMALE \cdot SOUTH)+e\qquad (7.16)
  \end{array}
$$

De donde,
$$
E(WAGE)
  \left\{
    \begin{array}{rl}
      \beta_1+\beta_2EDUC+\delta_1BLACK + \delta_2FEMALE + \gamma(BLACK\cdot FEMALE) & \mbox{SOUTH=0}\\
      (\beta_1+\theta_1) + (\beta_2+\theta_2)EDUC+(\delta_1+\theta_3)BLACK +& \mbox{SOUTH=1}\\
      (\delta_1+\theta_4)FEMALE+(\gamma+\theta_5)(BLACK\cdot FEMALE)
    \end{array}
  \right.
$$

Los efectos inderectos nos dicen que por pertenecer al sur la educación sea distintas (EDUCxSOUTH)

#### Test de constraste WALD
Nuestra hipótesis nula estará dada por

$$H_0:\theta_1=\theta_2=\theta_3=\theta_4=\theta_4=0.$$


```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wage = lm(WAGE~EDUC+BLACK+FEMALE+I(BLACK*FEMALE)+SOUTH+I(EDUC*SOUTH)+I(BLACK*SOUTH)+I(FEMALE*SOUTH)+I(BLACK*FEMALE*SOUTH),data=salario)
summary(wage)
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
wald.test(vcov(wage),coef(wage),Terms = 6:10)
```

Al 10 por ciento es representativo pero no así al 5 por ciento.


## 7.3.4 Variables temporales

Se puede analizar dummies estacionales o anuales o impáctos de tasas., porejemplo:

$$
ITC = 
  \left\{
    \begin{array}{rl}
      1 & 1962-1965,1970-1986\\
      0 & otro.
    \end{array}
  \right.
$$

Entonces,

$$INV_t =\beta_1+\delta ITC_t + \beta_2GBP_t + \beta_3 GNP_{t-1}+e_t$$
Nos preguntamos si la incidencia fiscal tiene incidencia sobre la inversión.


# 7.4 Interacción entre variables continuas.

Con dummies continuas como la edad.

Analizaremos el gasto en pizza que depende del ingreso y la edad.

$$PIZZA=\beta_1+\beta_2AGE + \beta_3INCOME + e \qquad (7.17)$$

Donde el efecto de aumentar en una unidad la renta de esa persona sobre el consumo de pizza nos viene dado por,

$$\dfrac{\partial E(PIZZA)}{\partial INCOME}=\beta_3.$$

Corremos la regresión

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
pizza = lm(PIZZA~AGE+INCOME,data=gasto)
summary(pizza)
```

Por otro lado, podemos ver otro modelo

$$PIZZA=\beta_1+\beta_2AGE + \beta_3INCOME + \beta_4(AGE\cdot INCOME) + e \qquad (7.17)$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
pizza1 = lm(PIZZA~AGE+INCOME+I(AGE*INCOME),data=gasto)
summary(pizza1)
```

Donde,
$$\dfrac{\partial E(PIZZA)}{\partial AGE}=\beta_2+\beta_4 INCOME$$
$$\dfrac{\partial E(PIZZA)}{\partial INCOME}=\beta_2+\beta_4AGE$$

Podemos calcular también el impacto de la edad para distintos niveles de renta.

$$
  \begin{array}{rcl}
    \dfrac{\partial E(INCOME)}{\partial AGE}&=&b_2+b_4INCOME\\\\
    &=& -2.98 - 0.00016INCOME
  \end{array}
$$

$$ = \left\{\begin{array}{rcl}
      -6.98 \mbox{ para INCOME} &=&  25000\\
      -17.40 \mbox{ para INCOME} &=& 90000
\end{array}\right.$$
  
Cuanto más renta tiene menos pizza se consume.


# 7.5 Modelos Log-lineal

## 7.5.1 Variables Dummy

Sea,

$$\ln(WAGE)=\beta_1+\beta_2EDUC+\delta FEMALE \qquad (7.19)$$

Donde,

$$
\ln(WAGE) =
  \left\{
    \begin{array}{rl}
      \beta_1+\beta_2EDUC & MALES\\
      (\beta_1+\delta)+\beta_2EDUC & FAMALES
    \end{array}
  \right.
$$

\begin{itemize}
  \item para comprar R2 tendremos que trabajar en R2 de terminos equivalentes.
  \item Para interpretar los resultados debemos multiplicar Los coeficientes por $100$. Se utiliza porcentajes.
\end{itemize}

\textbf{\boldmath Como se interpreta $\delta$?}

### Un calculo aproximado

$$\delta = \triangle \ln(WAGE)  =\ln(WAGE)_{FEMALES}-\ln(WAGE)_{MALES}$$

Luego,

$$\ln(WAGE)=0.9290+0.1026EDUC-0.2526 FEMALE$$

Así, decimos que si el trabajador en vez de ser mujer fuera hombre ganaría un 25 por ciento. Ya que multiplicamos $0.25*100$.

### Un calculo exacto.

$$\ln(WAGE)_{FEMALES}-\ln(AGE)_{MALES}=\ln\left(\dfrac{WAGE_{FEMALES}}{WAGE_{MALES}}\right)=\delta.$$

$$\dfrac{WAGE_{FEMALES}}{WAGE_{MALES}}=e^\delta$$

$$\dfrac{WAGE_{FEMALES}}{WAGE_{MALES}}-\dfrac{WAGE_{MALES}}{WAGE_{MALES}}=\dfrac{WAGE_{FEMALES}-WAGE_{MALES}}{WAGE_{MALES}}=e^\delta-1$$

## 7.5.2 Interacción y términos cuadráticos.

$$\ln(WAGE)=\beta_1+\beta_2EDUC+\beta_3 EXPER+\gamma(EDUC\times EXPER)+e \qquad (7.20)$$

De donde, calculamos el efecto de un año de experiencia  

$$\dfrac{\triangle \ln(WAGE)}{\triangle EXPER}\bigg|_{EDUC\; fixed}=\beta_3+\gamma EDUC$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
lnWAGE = lm(log(WAGE)~EDUC+EXPER+I(EDUC*EXPER),data=salario)
summary(lnWAGE)
```

#### ¿Como calculamos un año adicional de experiencia para una persona que tenga 16 años de educación?

$$\dfrac{\triangle \ln(WAGE)}{\triangle EXPER}=\beta$$




```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
#library
library(hexView)
library(aod)
library(broom)
library("lmtest")
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
# data
renta = readEViews("../data/Suposto 2.1 Modelos de renda. Hill 2008.WF1")
```

# Sesgo de omisión de variables.

- Se produce cuando omitimos una variable significativa para un modelo. Esto haría que un $\beta_i=0$.

- Cuando se omite una variable significativa, entonces aumentamos la perturbación, lo que se tiene autocorrelación.

- Podemos analizar la correlación de cada variable.

### Que ocurre cuando agregas variables relevantes e irrelevantes.

- Cuando agregamos una variable irrelevantes, las varianzas de los otros estimadores tienden a elevarse.

### Precisión de los estimadores

$$t_i=\left|\dfrac{b_i}{\sqrt{S^2 b_i}}\right|$$
$$
  \begin{array}{rcl}
    b_i &=& \mbox{Valor del estimador}\\
    \sqrt{S^2b_i} &=& \mbox{Varianza}
  \end{array}
$$

- Cuando incluimos variables irrelevantes incrementamos la varianza $\sqrt{S^2b_i}$ y nos dará ratios $t_i$ más pequeños, es decir más imprecisos. 

### Cuestiones que especificar

1. Revisar la teoría económica y compararla.

2. Es importante las significatitividad.

3. Se debe tomar criterios de selección. Que nos permite cual es el mejor modelo.

4. Test reset es menos importante que los R2 equivalentes. Teoricamente tienes buenas cualidades.

#### Criterios de selección

1. R2 ajustado

2. AIC

3. SC(BIC)

- El R2 no nos vale si tiene distintos de variables explicativas, por lo que veremos el R2 cuadrado ajustado.

- EL akiake information criterion (AIC), se relaciona con la suma de cuadrado de los errores, por lo que se elije el que tiene un modelo con el valor inferior.

- Schwarz criterion, de igual forma es la que tiene el valor inferior.


## El Criterio T RESET

Teóriamente nos indicaría:

- Si estamos omitiendo variables importantes.
- Si estamos incluyendo variables irrelevantes.
- Si la forma funcional es correcta o incorrecta.
- Si se están cumpliendo los supuestos del modelo clásico.

Sea,
$$y=\beta_1+\beta_2x_2+\beta_3x_3+e$$
de donde predecimos

$$\hat{y}=b_i+b_2x^2+b_3x_3$$

Luego, generamos dos modelos artificiales

$$y=\beta_1+\beta_2x_2+\beta_3x_3+\gamma_1\hat{y}^2+e$$
y

$$y=\beta_1+\beta_2x_2+\beta_3x_3+\gamma_1 \hat{y}^2 + \gamma_2 \hat{y}^{3s}+e$$

Después aplicando RESET, tenemos

$H_0:\gamma_1=0\qquad F=5.984\quad p-value=0.015$  
$$H_0:\gamma_1=\gamma_2=0\qquad F=3.123 \quad p-value=0.045$$

Pero no nos dice cual es mejor.

### Modelo 1

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
renta_fam = lm(FAMINC~HEDU+WEDU,data=renta)
summary(renta_fam)
AIC(renta_fam)
BIC(renta_fam)
```

### Modelo 2
```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
renta_fam1 = lm(FAMINC~HEDU,data=renta)
summary(renta_fam1)
AIC(renta_fam1)
BIC(renta_fam1)
```

#### Correlación multiple modelo 3
```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
cor(renta[,c("FAMINC","HEDU","WEDU","KL6","XTRA_X5","XTRA_X6")])
```

### Modelo 3
```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
renta_fam2 = lm(FAMINC~HEDU+WEDU+KL6,data=renta)
summary(renta_fam2)
AIC(renta_fam2)
BIC(renta_fam2)
```

### Modelo 4
```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
renta_fam3 = lm(FAMINC~HEDU+WEDU+KL6+XTRA_X5+XTRA_X6,data=renta)
summary(renta_fam3)
AIC(renta_fam3)
BIC(renta_fam3)
```


- El mejor modelo será el modelo 3, por lo que podemos tal vez utilizar el T RESET, que nos indircará si es mejor un modelo lineal o un modelo cuadrático.

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
resettest(renta_fam2 , power=2, type=c("fitted"))
```

Por lo tanto, rechazamos la hipótesis nula. Y por lo tanto la forma cuadrática es mejor que la forma lineal.

#### Consideraremos un polinomio de grado 3

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
resettest(renta_fam2 , power=2:3, type=c("fitted"))
```
- Por lo que rechazamos la hipótesis $\gamma_1=\gamma_2=0$, de donde el modelo cúbico es superior al modelo lineal.
- Lo que no nos da si el cuadrado o el cúbico es mejor.
- En Conclusión a nivel práctico el Test RESET no tiene mucha utilidad.


## Multicolinialidad 

Correlación entre las distintas variables explicativas. Lo que afecta a la varianza de los estimadores.

Sea,

$$y=\beta_1+\beta_2x_2+\beta_3x_3+e$$

La varianza de los estimadores de mínimos cuadrados para $\beta_2$ es:

$$Var(b_2)=\dfrac{\sigma_2}{\left(1-r^2_{23}\right)\sum\limits_{i=1}^n \left(x_2-\overline{x}_2\right)^2}$$

$r_{23}^2$ =  correlación entre variables 2 y 3

- Si $r$ (correlación) es grande entonces la varianza del estimador es grande y por lo tanto no podemos realizar una buena regresión.

- Si $x_2=2x_3$ entonces la relación no tiene multicolinialidad, de lo contrario $x_2=x_3$  la cual mantiene una relación.





```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE,out.width="50%"}
#library
library(hexView)
#data
gas = readEViews("../data/Suposto 2.2. Modelos consumo gasolina. Hill 2008.WF1")
``` 

# Multicolinialidad

Podemos hablar de dos tipos:

#### 1. Perfecta
Existe una relación exacta entre dos variables explicativas. En la práctica no ocurre , lo que es importante 

#### 2. Elevada
Si la varianza crece los ratios disminuyen y existe multicolinialidad.


### Supuesto 2.2

#### Tabla de correlaciones


```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
cor(gas[,c("MPG","CYL","ENG","WGT")])
```

- la que más está relacionada en WGT. 

### MODELO 1

$$MPG=\beta_1 + \beta_2 CYL + e$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
model1 = lm(MPG~CYL,data=gas)
summary(model1)
```

#### ¿Que ocurre si colocamos dos variables correlacionadas entre si?

### MODELO 2

$$MPG=\beta_1 + \beta_2 CYL + ENG + WGT + e$$

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
model2 = lm(MPG~CYL+ENG+WGT,data=gas)
summary(model2)
```
El ratio de precisión es $t-value$. Debería ser alto para no tener una varianza controlada.

#### ¿Cómo podemos detectar correlaciones?

- La herramienta más útil son los coeficientes de correlaciones lineales. Si este coeficiente es alto, podemos decir que tiene alta correlación entre si.

- El determinante del matríz de correlaciones. Es el que detecta mejor las relaciones. Cuanto mayor sea el coeficiente de correlaciones simples menor será el determinante.

- Pero existe uno mejor aún, que es el determinante de la matríz de correlaciones entre los regresores.

#### ¿Que hacemos para corregir?

- Incrementamos la variable muestral. Pero es poco útil a nivel práctico.

- Detectar la variable que tiene más correlación y eliminarla. Es la más útil a nivel práctico.

- Incluir información en el modelo. Es poco útil a nivel práctico



# TEMA 5.

Partamos de un modelo 

$$Y_t=f(X_1+X_{2t}+\ldots + X_{kt})+e_t$$

donde, $Cov(X_{it},E_t) = 0$ es decir, las variables explicativas no están relacionadas con la perturbación. Ya que suponemos que no son estocásticas o no aleatorias.
Dado que $E(X_{it})$ es constante, entonces 
$$Cov(X_{it},E_t)=\left[X_{it}-E(X_{it})\right]\left[E_t-E(E_t)\right]=\left(X_{it}-X_{it}\right)\left[E_t-E(E_t)\right]=0\left[E_t-E(E_t)\right]=0.$$

#### ¿Qué ocurriría si la Cov no es 0?

$$Cov(X_{it},E_t)\neq 0.$$

- Si realizamos con el método de mínimos ordinarios, nos dará que los coeficientes son inconsistentes. 

- En el modelo clásico a las $X$ que no están asociadas con la perturbación se las llama variables exógenas.

- Cuando $X$ está relacionada con la perturbación se la llama variable endógena. Puede ocurrir cuando son variables aleatorias o estocásticas por naturaleza.

#### Ejemplo

Modelo de turismo

$$Y_t=f(X_{t-1},X_{1t},\ldots,X_{kt})+E_t$$

Donde se incluye una variable retardada, que es una variable endógena. 

$$Y_{t-1}=f(T_{t-2},X_{1t-1},\ldots,X_{kt-1})+E_{t-1}$$

- Otro caso es cuando tenemos errores de medida en las variables $X$.

-Omitimos variables relevantes, se puede generar endogeneidad.

### Métodos de variables instrumentales.

Como no podemos utilizar $Y_{t-1}$, entonces utilizamos una variables $Z_t$ donde, 
$$Cov(Y_{t-1},Z_t)\neq 0 \qquad \mbox{y}\qquad Cov(Z_t, E_t)=0.$$

- Que este relacionado con la variable que se sustituye.
- Y no esté relacionada con la perturbación.

Pero esto es difícil, por lo que debemos utilizar muchas veces más de una $Z_t$.

#### Estimamos de la siguiente manera

$$\hat{\beta}=\left(Z'X\right)^{-1}Z'Y$$

- Se utiliza el mínimo cuadrado en dos etapas. 


# Capítulo 10

- Las variables son aleatorias.
- Puede ocurrir que la cov es igual a 0 (exógena) o distintos de cero (endógenas).
- Que ocurre cuando se trabaja con muestras pequeñas y grandes. Consistencia de los datos.
- La condición de consistencia tiende al parámetro a medida que crece el tamaño muestral.
$$\lim_{N\to 2}b_i \to \beta_i.$$

Si tenemos relación entre las variables y la perturbación no podemos estimar por mínimos cuadrados ordinarios.

- Los errores son los estimadores de la perturbación. 
- Si graficamos los errores y la variable $x$ y se tiene correlación entonces no podemos usar los mínimos cuadrados ordinarios.





```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
library(hexView)
library(sandwich)
library(gmm)
educ = readEViews("../data/Suposto 1.3 Modelos salarios.3Edition.wf1")
WAGE = readEViews("../data/datos suposto 5.2.wf1")
``` 

Sea,

$$Y=\beta_1+\beta_1X_1+\beta_3X_2+e$$

- Si $\beta_3X_2+e$ no se incluye en el modelo entonces es parte de $e$.

- Si no añadimos $X_2$ en el modelo, habrá una correlación entre $X_1$ y $e$. Por lo tanto, no podremos estimar por lo mínimos cuadrados ordinarios.

### Casos más usuales donde existe correlación entre las $X's$ y los errores.

#### 1. 
Tenemos un modelo de ecuaciones simultaneas: Una variable puede estar como variables explicativa y en otra puede ser una variable explicada. 

Ejemplo: El precio y la producción.

#### 2.
Cuando se mide una variable con error.

Por ejemplo, $x$ es la renta anual permanente y $y$ es el ahorro anual. Existe momentos que no se puede encontrar datos exactos de renta por lo que se utiliza datos aproximados, (ingresos corrientes). donde provoca un error de medida. Es decir, Si $x-u$ es un equivalente a los datos de renta anual permanente, entonces

$$\begin{array}{rcl}
  y &=& \beta_1 + \beta_2 x^* + v_i\\\\
  &=& \beta_1+\beta_2(x-u)+v\\\\
  &=& \beta_1+\beta_2x+(v-\beta_2u)\\\\
  &=&\beta_1+\beta_2x+e
\end{array}$$

de donde,

$$Cov(x,e)=E(xe)=E\left[(x^*+u)(v-\beta_2u)\right]=E\left(-\beta_2u^2\right)=-\beta_2\sigma^2_u\neq 0$$


#### 3. 
Cuando se emiten variables que están relacionadas entre ellas.

Ejemplo:

$$ln(WAGE)=\beta_1+\beta_2EDUC+\beta_3EXPER + \beta_4EXPER^2+e$$

de donde,

$$Cov(EDUC,e)\neq 0.$$
La variable EDUC puede sestar sobre estimado, ya que parte de EDUC está en la perturbación.

#### 4. 
Incluimos valores retardados del regresando, $t-1$ y a perturbación.


## 10.3 Estimadores basados en métodos de los momentos.

- Si existe endogeneidad entre la variable y el error.

Lo mismo que en estadística, trasladaremos el método de los moementos a la econométrica.

- Para un modelo de regresión lineal el método de los momentos es:

$$y=\beta_1+\beta_2x+e$$

donde el primer momento sería,

$$E(e_i)=0 \quad \Rightarrow \quad E(y_i-\beta_i-\beta_2x_i)=0.$$

El segundo momentos es:

$$E(xe)=0\quad \Rightarrow \quad E\left[x(y-\beta_1-\beta_2x)\right]=0.$$

- Los $\beta$s no los conocemos por lo que

$$\dfrac{1}{N}\sum (y_i-b_i-b_2x_i)=0$$

$$\dfrac{1}{N}\sum x_i(y_i-b_i-b_2x_i)=0$$

Por lo tanto,

$$b_2=\dfrac{\sum (x_i-\overline{x})(y_i-\overline{y})}{\sum (x_i-\overline{x})^2}$$

$$b_1=\overline{y}-b_2\overline{x}$$

#### ¿Qué ocurre si la x está relacionado por la perturbación?

- Debemos sustituir esa $x$ por un instrumento $z$ el cual debe cumplir:

$$Cov(Y_{t-1},Z_t)\neq 0 \qquad \mbox{y}\qquad Cov(Z_t, E_t)=0.$$

Que este relacionado con la variable que se sustituye. Y no esté relacionada con la perturbación.

Lo que buscaremos este instrumento $Z$:

$$E(ze)=0\quad \rightarrow E\left[z(y-\beta_1-\beta_2x)\right]=0$$

de donde,

$$\dfrac{1}{N}\sum (y_i-b_i-b_2x_i)=0$$

$$\dfrac{1}{N}\sum z_i(y_i-b_i-b_2x_i)=0$$

Así,

$$\hat{\beta_2}=\dfrac{N\sum z_iy_i-\sum z_i\sum y_i}{N\sum z_i x_i - \sum z_i \sum x_i}=\dfrac{\sum (z_i-\overline{z})(y_i -\overline{y})}{\sum(z_i-\overline{z})(x_i-\overline{x})}$$

$$\hat{\beta_i}=\overline{y}-\hat{\beta_2}\overline{x}.$$

#### Estimamos la varianza de beta dos.

- el estimador de la variable instrumental se aproxima a una distribución normal, siempre que la muestra sea grande.

$$\hat{\beta_2}\sim N\left(\beta_2,\dfrac{\sigma^2}{r_{zx}^2 \sum (x_i-\overline{x})^2}\right)$$
- El error de la varianza será

$$\hat{\sigma}^2_{IV}=\dfrac{\sum\left(y_i-\hat{\beta}_1-\hat{\beta}_2x_i\right)^2}{N-2}.$$

- Tenemos también la varianza de $\beta_2$ estimada

$$Var(\hat{\beta}_2)=\dfrac{\sigma^2}{r_{zx}^2\sum (x_i-\overline{x})^2}=\dfrac{Var(b_2)}{r_{zx}^2}$$
En la práctica tiene una varianza mayor y son consistentes.

- Supongamos que $x_k$ esta relacionada con la perturbación.

por lo que utilizaremos el mínimos cuadrados en dos etapas. Lo que es caso particular del método de los momentos.

### Métodos de dos etapas

- Estimamos la variable que este estimada con la perturbación con todas las variables explicativas mas el instrumento.

Sea el modelo teórico,

$$x_K=\gamma_1+\gamma_2x_2+\cdots + \gamma_{K-1}x_{K-1}+\theta_1z_1+\cdots + \theta_i z_i + v_K$$

donde estimamos:

$$\hat{x}_K = \hat{\gamma}_1 + \hat{\gamma}_2x_2+\cdots + \hat{\gamma}_{K-1}+\hat{\theta}_1z_1+\cdots + \hat{\theta}_iz_i.$$

Y los valores estimados de $x_K$ los incluimos en la segunda etapa como instrumento,

$$y=\beta_1+\beta_2x_2+\cdots +\beta_K\hat{x}_k + e^*$$

- Estimaríamos también la varianza de la estimación

$$\hat{\sigma}_{IV}^2 = \dfrac{\sum \left(y_i-\hat{\beta}_1 - \hat{\beta}_2 x_2 - \cdots - \hat{\beta}_K x_{Ki}\right)^2}{N-K}$$

#### ¿Cómo aplicamos el método de mínimos cuadrados en dos etapas al modelo simple?

- En la regresión simple. si $x$ es endogena y tenemos $L$ instrumentos:
$$\hat{x}=\hat{\gamma}_1+\hat{\theta}_i z_1+\cdots + \hat{\theta}_iz_i.$$

La condición de momoentos de dos muestras son

$$\dfrac{1}{N}\sum \left(y_i-\hat{\beta}_1 - \hat{\beta}_2 x_i\right)=0$$
$$\dfrac{1}{N}\sum \hat{x}_i\left(y_i-\hat{\beta}_1 - \hat{\beta}_2 x_i\right)=0$$

- Luego, estimamos $\hat{\beta}_2$,

$$\hat{\beta}_2=\dfrac{\sum (\hat{x}_i-\overline{\hat{x}})(y_i-\overline{y})}{\sum (\hat{x}_i - '\overline{\hat{x}})(x_i-\overline{x})}=\dfrac{\sum (\hat{x}_i-\overline{x})(y_i-\overline{y})}{\sum (\hat{x}_i-\overline{x})(x_i-\overline{x})}$$

$$\hat{\beta}_1 = \overline{y}-\hat{\beta}_2 \overline{x}.$$

- Supongamos que utilizamos un nuevo instrumento,

$$E(z_2e)=E\left[z_2(y-\beta_1-\beta_2x)\right]=0$$
- Como serían las ecuaciones de los momentos?

$$\dfrac{1}{N}\sum \left(y_i-\hat{\beta}_1-\hat{\beta}_2 x_i\right)=\hat{m}_i=0$$

$$\dfrac{1}{N}\sum z_{i1}\left(y_i-\hat{\beta}_1-\hat{\beta}_2 x_i\right)=\hat{m}_2=0$$
$$\dfrac{1}{N}\sum z_{i2}\left(y_i-\hat{\beta}_1-\hat{\beta}_2 x_i\right)=\hat{m}_3=0$$

#### ¿Cómo sabriamos que los isntrumentos son adecuados o no?

Sea,

$$x_K=\gamma_1+\gamma_2x_2+\cdots + \gamma_{K-1}x_{K-1}+\theta_1z_1+ v_K$$

- Para ello debemos ver que $\theta_1\neq 0$, y $z_1$ es significativo, ya que explica bien el comportamiento de $x_K$

- ¿Qué pasa si tenemos $L$ instrumentos, cómo sabemos que son adecuados?

$$x_K=\gamma_1+\gamma_2x_2+\cdots + \gamma_{K-1}x_{K-1}+\theta_1z_1+ \cdots + \theta_iz_i + v_K$$

donde realizariamos un contraste, $\theta_1=\theta_2 \ldots = 0.$

- En la práctica si nos da un $F$ grande, entonces son instrumentos buenos y lo contrario.


### Considerar el modelo con una variable instrumental MOTHEREDUC:

Sea,
$$EDUC=9.775 + 0.0489EXPER-0.0013EXPER^2+0.2677 MOTHEREDUC$$
- Si dividimos $0.26/0.0311)$ que es su desviación típica, entonces nos da ratio t $8.6$ que es un ratio grande lo que es significativa, luego $t$ lo elevamos al cuadrado lo que vemos que $F>10$, así el isntrumento es fuerte.

- Luego,

$$\ln(WAGE)=0.1982+0.0493\hat{EDUC}+0.0449EXPER-0.0009EXPER^2$$

- Lo podemos ver que el salario estaba sobre estimado. Ya que el salario solo incrementará un  $4.9\%$ pro un año de eduacación.

- Pero si calculamos el ratio T $0.0493/0.0374$ que es su Desviación típica, lo que no es significativa. Por lo que tenemos que seguir mejorando metiendo un instrumento más

#### Usamos FATHEREDUC

$$EDUC=\gamma_i+\gamma_2EXPER+\gamma_3EXPER^2 + \theta_1MOTHEREDUC+\theta_2FATHEREDUC+v$$

$$EDUC=0.0452EXPER-0.0010XPER^2 + 0.1576MOTHEREDUC+0.1895FATHEREDUC+v$$

- Los dos instrumentos son muy significativos

LUEGO,

$$\ln(WAGE)=0.0481+0.0614\hat{EDUC}+0.442EXPER-0.0009EXPER^2$$

- Si dividimos $0.0614/0.0314$ entonces nos da ratio t $2$ lo que es significativa.

## TEST DE ESPECIFICACIÓN

#### 1. ¿Cómo analizamos que la covarianza de xe es distintos de cero?
Resolvemos con el test de Hausman

$$Cov(xe)\neq0$$
si es distintos de cero entonces,

#### 2. ¿Cómo analizamos si la covarianza entre z y el error es igual a cero?

Resolvemos con el test de SARGAN/HANSEN

$$Cov(ze)=0$$

Lo que se tiene que ver es si la $x$ es endógena o no.


### EL test de Hausman

- La hipótesis nula es $H_0:Cov(x,e)=0$ y $H_1:Cov(x,e)\neq 0$.

- Es un test por etapas:

Sean,

$$y=\beta_1+\beta_2x+e$$

y sea $z_1$ y $z_2$ variables instrumentales de $x$.

De donde, estimamos el modelo $x=\gamma_1+\theta z_1 + \theta_2 x_2 + v$ por mínimos cuadrados y obtenemos los residuos

$$\hat{v}=x-\hat{\gamma}_1 - \hat{\theta}_1 z_1 - \hat{\theta}_2 z_2.$$

- Estos errores los llevo a la ecuación inicial, por lo tanto

$$y=\beta_1+\beta_2x+\delta \hat{v}+e$$

Luego, contrastamos si $H_0:\delta=0$ $H_1:\delta\neq 0$. Es decir, no existe o si existe correlación entre $x$ y $e$. 


### Test de Hansen
¿Cómo contrastamos si Cov(z,e)=0 ?

- En una primera etapa, vamos a estimar $y$ en función de todas las variables explicativas y de todos los instrumentos.

- En la segunda etapa calculamos todos los residuos.

- Calculamos el R2


## Ejemplo

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
logIngresos = lm(log(INGRESOS)~S+EXPE+PNT+SEXO+NEGRO+HISP,data=WAGE)
summary(logIngresos)
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
twoStep=gmm(log(INGRESOS)~S+EXPE+PNT+SEXO+NEGRO+HISP,~S+EXPE+SPAD+SEXO+NEGRO+HISP,type = "twoStep",data=WAGE)
summary(twoStep)
```

```{r, fig.align="center", fig.height=2, fig.width=3, echo=FALSE, warning=FALSE}
twoStep2=gmm(log(INGRESOS)~S+EXPE+PNT+SEXO+NEGRO+HISP,~S+EXPE+SPAD+SMAD+NHERMANOS+BIBLIOT+SEXO+NEGRO+HISP,type = "twoStep",data=WAGE)
summary(twoStep2)
```

$H_0: $ los instrumentos son válidos

$H:1:$ los instrumentos no son válidos.



