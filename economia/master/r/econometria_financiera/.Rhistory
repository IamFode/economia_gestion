w3 <- (mu_XOM / sigma2_XOM) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.var[1]
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.var[1]
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.var[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.var[1]
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.var[1]
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.var[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue", ylim = c(0, 1))
lines(data$Date, weights[, 2], col = "red")
# Calcular las ponderaciones óptimas
w1 <- (mu_AAPL / sigma2_AAPL) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w2 <- (mu_NLY / sigma2_NLY) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w3 <- (mu_XOM / sigma2_XOM) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
n
weights <- matrix(NA, nrow = n, ncol = 3)
weights
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$pred.var[1]
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$pred.var[1]
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.mean[1]
sigma2_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$pred.var[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
predict(model_AAPL, n.ahead = 1, n.start = i)
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$meanForecast
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$meanForecast
sigma2_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$standardDeviation
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$meanForecast
sigma2_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$standardDeviation
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$meanForecast
sigma2_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$standardDeviation
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue", ylim = c(0, 1))
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue", ylim = c(0, 1))
weights
data=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
data$DATE = NULL
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Ajustar los modelos GARCH a los rendimientos de cada stock
model_AAPL <- garchFit(formula = ~garch(1, 1), data = ret_AAPL, cond.dist = "QMLE")
model_NLY <- garchFit(formula = ~garch(1, 1), data = ret_NLY, cond.dist = "QMLE")
model_XOM <- garchFit(formula = ~garch(1, 1), data = ret_XOM, cond.dist = "QMLE")
# Obtener la media condicional y la varianza condicional de cada stock
mu_AAPL <- predict(model_AAPL, n.ahead = 1)$meanForecast
sigma2_AAPL <- (predict(model_AAPL, n.ahead = 1)$standardDeviation)^2
mu_NLY <- predict(model_NLY, n.ahead = 1)$meanForecast
sigma2_NLY <- (predict(model_NLY, n.ahead = 1)$standardDeviation)^2
mu_XOM <- predict(model_XOM, n.ahead = 1)$meanForecast
sigma2_XOM <- (predict(model_XOM, n.ahead = 1)$standardDeviation)^2
# Calcular las ponderaciones óptimas
w1 <- (mu_AAPL / sigma2_AAPL) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w2 <- (mu_NLY / sigma2_NLY) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w3 <- (mu_XOM / sigma2_XOM) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$meanForecast
sigma2_AAPL_i <- (predict(model_AAPL, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$meanForecast
sigma2_NLY_i <- (predict(model_NLY, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$meanForecast
sigma2_XOM_i <- (predict(model_XOM, n.ahead = 1, n.start = i)$standardDeviation)^2
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Estadísticos descriptivos de las ponderaciones óptimas
descriptive_stats <- data.frame(
"Stock" = c("AAPL", "NLY", "XOM"),
"Media" = colMeans(weights),
"Desviación Estándar" = apply(weights, 2, sd),
"Mínimo" = apply(weights, 2, min),
"Máximo" = apply(weights, 2, max)
)
print(descriptive_stats)
mean(data$AAPL)
plot(weights)
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue", ylim = c(0, 1))
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue")
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1])
weights
mu_AAPL_i
# Ajustar los modelos GARCH a los rendimientos de cada stock
model_AAPL <- garchFit(formula = ~garch(1, 1), data = ret_AAPL, cond.dist = "QMLE")
# Cargar paquetes necesarios
library(rugarch)
library(ggplot2)
library(reshape2)
data=readEViews("data/Tarea2.wf1",time.stamp = FALSE)
data$DATE = NULL
# Ajustar los modelos GARCH a las series de rendimientos
model_AAPL <- ugarchspec(mean.model = list(armaOrder = c(0, 0)), variance.model = list(model = "sGARCH"), distribution.model = "norm")
fit_AAPL <- ugarchfit(spec = model_AAPL, data = data$AAPL)
model_NLY <- ugarchspec(mean.model = list(armaOrder = c(0, 0)), variance.model = list(model = "sGARCH"), distribution.model = "norm")
fit_NLY <- ugarchfit(spec = model_NLY, data = data$NLY)
model_XOM <- ugarchspec(mean.model = list(armaOrder = c(0, 0)), variance.model = list(model = "sGARCH"), distribution.model = "norm")
fit_XOM <- ugarchfit(spec = model_XOM, data = data$XOM)
# Obtener el número total de observaciones
n <- nrow(data)
# Crear una matriz para almacenar las ponderaciones óptimas
weights <- matrix(NA, nrow = n, ncol = 3)
# Calcular las ponderaciones óptimas en cada momento
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional de cada stock en el momento i
forecast_AAPL <- ugarchforecast(fit_AAPL, n.ahead = 1, n.roll = i)
mu_AAPL_i <- forecast_AAPL@forecast$seriesFor[1]
sigma2_AAPL_i <- forecast_AAPL@forecast$sigmaFor[1]
forecast_NLY <- ugarchforecast(fit_NLY, n.ahead = 1, n.roll = i)
mu_NLY_i <- forecast_NLY@forecast$seriesFor[1]
sigma2_NLY_i <- forecast_NLY@forecast$sigmaFor[1]
forecast_XOM <- ugarchforecast(fit_XOM, n.ahead = 1, n.roll = i)
mu_XOM_i <- forecast_XOM@forecast$seriesFor[1]
sigma2_XOM_i <- forecast_XOM@forecast$sigmaFor[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Calcular las ponderaciones óptimas en cada momento
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional de cada stock en el momento i
forecast_AAPL <- ugarchforecast(fit_AAPL, n.ahead = 1, n.roll = 0)
mu_AAPL_i <- forecast_AAPL@forecast$seriesFor[i]
sigma2_AAPL_i <- forecast_AAPL@forecast$sigmaFor[i]
forecast_NLY <- ugarchforecast(fit_NLY, n.ahead = 1, n.roll = 0)
mu_NLY_i <- forecast_NLY@forecast$seriesFor[i]
sigma2_NLY_i <- forecast_NLY@forecast$sigmaFor[i]
forecast_XOM <- ugarchforecast(fit_XOM, n.ahead = 1, n.roll = 0)
mu_XOM_i <- forecast_XOM@forecast$seriesFor[i]
sigma2_XOM_i <- forecast_XOM@forecast$sigmaFor[i]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
weights
# Obtener el número total de observaciones
n <- nrow(data)
# Crear una matriz para almacenar las ponderaciones óptimas
weights <- matrix(NA, nrow = n, ncol = 3)
# Calcular las ponderaciones óptimas en cada momento
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional de cada stock en el momento i
forecast_AAPL <- ugarchforecast(fit_AAPL, n.ahead = 1, n.roll = 0)
mu_AAPL_i <- forecast_AAPL@forecast$seriesFor[i]
sigma2_AAPL_i <- forecast_AAPL@forecast$sigmaFor[i]
forecast_NLY <- ugarchforecast(fit_NLY, n.ahead = 1, n.roll = 0)
mu_NLY_i <- forecast_NLY@forecast$seriesFor[i]
sigma2_NLY_i <- forecast_NLY@forecast$sigmaFor[i]
forecast_XOM <- ugarchforecast(fit_XOM, n.ahead = 1, n.roll = 0)
mu_XOM_i <- forecast_XOM@forecast$seriesFor[i]
sigma2_XOM_i <- forecast_XOM@forecast$sigmaFor[i]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional de cada stock en el momento i
forecast_AAPL <- ugarchforecast(fit_AAPL, n.ahead = 1, n.roll = i)
mu_AAPL_i <- forecast_AAPL@forecast$seriesFor[1]
sigma2_AAPL_i <- forecast_AAPL@forecast$sigmaFor[1]
forecast_NLY <- ugarchforecast(fit_NLY, n.ahead = 1, n.roll = i)
mu_NLY_i <- forecast_NLY@forecast$seriesFor[1]
sigma2_NLY_i <- forecast_NLY@forecast$sigmaFor[1]
forecast_XOM <- ugarchforecast(fit_XOM, n.ahead = 1, n.roll = i)
mu_XOM_i <- forecast_XOM@forecast$seriesFor[1]
sigma2_XOM_i <- forecast_XOM@forecast$sigmaFor[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
out.sample <- 100  # Valor de out.sample utilizado en el ajuste del modelo GARCH
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional de cada stock en el momento i
n.roll <- min(i, out.sample)  # Limitar n.roll según el valor de out.sample
forecast_AAPL <- ugarchforecast(fit_AAPL, n.ahead = 1, n.roll = n.roll)
mu_AAPL_i <- forecast_AAPL@forecast$seriesFor[1]
sigma2_AAPL_i <- forecast_AAPL@forecast$sigmaFor[1]
forecast_NLY <- ugarchforecast(fit_NLY, n.ahead = 1, n.roll = n.roll)
mu_NLY_i <- forecast_NLY@forecast$seriesFor[1]
sigma2_NLY_i <- forecast_NLY@forecast$sigmaFor[1]
forecast_XOM <- ugarchforecast(fit_XOM, n.ahead = 1, n.roll = n.roll)
mu_XOM_i <- forecast_XOM@forecast$seriesFor[1]
sigma2_XOM_i <- forecast_XOM@forecast$sigmaFor[1]
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
data=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
data$DATE = NULL
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Estimación del modelo para cada activo
fit_AAPL <- ugarchfit(spec, data = rer_AAPL)
library(hexView)
library(rugarch)
data=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
data$DATE = NULL
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Estimación del modelo para cada activo
fit_AAPL <- ugarchfit(spec, data = rer_AAPL)
# Estimación del modelo para cada activo
fit_AAPL <- ugarchfit(spec, data = ret_AAPL)
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)), mean.model = list(armaOrder = c(0, 0)))
# Estimación del modelo para cada activo
fit_AAPL <- ugarchfit(spec, data = ret_AAPL)
fit_NLY <- ugarchfit(spec, data = ret_NLY)
fit_XOM <- ugarchfit(spec, data = ret_XOM)
# Paso 4: Obtener la media condicional y la varianza condicional
mu_conditional <- c(fit_AAPL@fit$mu, fit_NLY@fit$mu, fit_XOM@fit$mu)
sigma_conditional <- c(fit_AAPL@fit$sigma, fit_NLY@fit$sigma, fit_XOM@fit$sigma)
# Paso 5: Calcular las ponderaciones óptimas
mu_target <- 0.15 / 100  # Rendimiento diario medio objetivo
# Cálculo de las ponderaciones óptimas
w <- (mu_conditional / sigma_conditional^2) / sum(mu_conditional^2 / sigma_conditional^2) * mu_target
# Paso 6: Graficar la evolución temporal de las ponderaciones
dates <- data$Date[-1]  # Fechas sin el primer elemento (no hay rendimiento para el primer día)
plot(dates, w[1, ], type = "l", col = "red", ylim = c(0, 1), xlab = "Fecha", ylab = "Ponderaciones", main = "Evolución temporal de las ponderaciones")
lines(dates, w[2, ], col = "blue")
lines(dates, w[3, ], col = "green")
legend("topright", legend = c("AAPL", "NLY", "XOM"), col = c("red", "blue", "green"), lty = 1)
# Paso 7: Calcular estadísticos descriptivos de las ponderaciones óptimas
statistics <- data.frame(Media = colMeans(w), DesviacionEstandar = apply(w, 2, sd))
print(statistics)
View(data)
data
datos <- datos[, c("AAPL", "NLY", "XOM")]  # Seleccionar las columnas relevantes
datos=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
datos$DATE = NULL
datos <- datos[, c("AAPL", "NLY", "XOM")]  # Seleccionar las columnas relevantes
datos
# 1. Encontrar el mejor modelo para las series temporales de rendimientos
library(rugarch)
# Función para ajustar un modelo GARCH
ajustar_modelo_garch <- function(datos) {
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")
fit <- ugarchfit(spec, data = datos)
return(fit)
}
modelos_garch <- lapply(datos, ajustar_modelo_garch)  # Ajustar modelos GARCH
# 2. Obtener la media condicional y la varianza condicional
medias_condicionales <- sapply(modelos_garch, function(modelo) {
sigma <- sigma(modelo)
return(mu(modelo) / sigma[length(sigma)])
})
varianzas_condicionales <- sapply(modelos_garch, function(modelo) {
return(sigma(modelo)^2)
})
# 2. Obtener la media condicional y la varianza condicional
medias_condicionales <- sapply(modelos_garch, function(modelo) {
sigma <- sigma(modelo)
return(mu(modelo) / sigma[length(sigma)])
})
# 1. Encontrar el mejor modelo para las series temporales de rendimientos
library(rugarch)
# Función para ajustar un modelo GARCH
ajustar_modelo_garch <- function(datos) {
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")
fit <- ugarchfit(spec, data = datos)
return(fit)
}
modelos_garch <- lapply(datos, ajustar_modelo_garch)  # Ajustar modelos GARCH
# 2. Obtener la media condicional y la varianza condicional
medias_condicionales <- sapply(modelos_garch, function(modelo) {
sigma <- sigma(modelo)
return(mu(modelo) / sigma[length(sigma)])
})
ponderaciones_optimas <- t(apply(medias_condicionales, 1, function(mu) {
calcular_ponderaciones_optimas(mu, varianzas_condicionales, rendimiento_deseado)
}))
# 4. Estadísticos descriptivos de las ponderaciones óptimas
estadisticos_descriptivos <- apply(ponderaciones_optimas, 2, function(ponderaciones) {
c(mean = mean(ponderaciones), sd = sd(ponderaciones))
})
# Gráfico de evolución temporal de las ponderaciones
fecha_inicio <- as.Date("2008-01-02")
fechas <- seq(fecha_inicio, length.out = nrow(datos), by = "day")
plot(fechas, ponderaciones_optimas[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación",
ylim = c(0, 1), main = "Evolución temporal de ponderaciones")
lines(fechas, ponderaciones_optimas[, 2], col = "red")
lines(fechas, ponderaciones_optimas[, 3], col = "blue")
legend("topright", c("AAPL", "NLY", "XOM"), col = c("black", "red", "blue"), lty = 1)
# Imprimir resultados
cat("Ponderaciones óptimas:\n")
print(ponderaciones_optimas)
cat("\nEstadísticos descriptivos de las ponderaciones óptimas:\n")
print(estadisticos_descriptivos)
# 1. Encontrar el mejor modelo para las series temporales de rendimientos
library(rugarch)
# Función para ajustar un modelo GARCH
ajustar_modelo_garch <- function(datos) {
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
distribution.model = "norm")
fit <- ugarchfit(spec, data = datos)
return(fit)
}
modelos_garch <- lapply(datos, ajustar_modelo_garch)  # Ajustar modelos GARCH
# 2. Obtener la media condicional y la varianza condicional
medias_condicionales <- sapply(modelos_garch, function(modelo) {
sigma <- sigma(modelo)
return(fitted(modelo) / sigma[length(sigma)])
})
varianzas_condicionales <- sapply(modelos_garch, function(modelo) {
return(sigma(modelo)^2)
})
# 3. Calcular las ponderaciones óptimas variando en el tiempo
rendimiento_deseado <- 0.0015
calcular_ponderaciones_optimas <- function(mu, sigma, rendimiento_deseado) {
w <- mu / sigma^2
suma_w <- sum(w)
ponderaciones <- w / suma_w * rendimiento_deseado
return(ponderaciones)
}
ponderaciones_optimas <- t(apply(medias_condicionales, 1, function(mu) {
calcular_ponderaciones_optimas(mu, varianzas_condicionales, rendimiento_deseado)
}))
ponderaciones_optimas <- t(apply(medias_condicionales, 1, function(mu) {
calcular_ponderaciones_optimas(mu, varianzas_condicionales, rendimiento_deseado)
}))
# 4. Estadísticos descriptivos de las ponderaciones óptimas
estadisticos_descriptivos <- apply(ponderaciones_optimas, 2, function(ponderaciones) {
c(mean = mean(ponderaciones), sd = sd(ponderaciones))
})
# Gráfico de evolución temporal de las ponderaciones
fecha_inicio <- as.Date("2008-01-02")
fechas <- seq(fecha_inicio, length.out = nrow(datos), by = "day")
plot(fechas, ponderaciones_optimas[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación",
ylim = c(0, 1), main = "Evolución temporal de ponderaciones")
lines(fechas, ponderaciones_optimas[, 2], col = "red")
lines(fechas, ponderaciones_optimas[, 3], col = "blue")
legend("topright", c("AAPL", "NLY", "XOM"), col = c("black", "red", "blue"), lty = 1)
# Imprimir resultados
cat("Ponderaciones óptimas:\n")
print(ponderaciones_optimas)
cat("\nEstadísticos descriptivos de las ponderaciones óptimas:\n")
print(estadisticos_descriptivos)
data=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
data$DATE = NULL
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Ajustar los modelos GARCH a los rendimientos de cada stock
model_AAPL <- garchFit(formula = ~garch(1, 1), data = ret_AAPL, cond.dist = "QMLE")
model_NLY <- garchFit(formula = ~garch(1, 1), data = ret_NLY, cond.dist = "QMLE")
model_XOM <- garchFit(formula = ~garch(1, 1), data = ret_XOM, cond.dist = "QMLE")
# Obtener la media condicional y la varianza condicional de cada stock
mu_AAPL <- predict(model_AAPL, n.ahead = 1)$meanForecast
sigma2_AAPL <- (predict(model_AAPL, n.ahead = 1)$standardDeviation)^2
mu_NLY <- predict(model_NLY, n.ahead = 1)$meanForecast
sigma2_NLY <- (predict(model_NLY, n.ahead = 1)$standardDeviation)^2
mu_XOM <- predict(model_XOM, n.ahead = 1)$meanForecast
sigma2_XOM <- (predict(model_XOM, n.ahead = 1)$standardDeviation)^2
# Calcular las ponderaciones óptimas
w1 <- (mu_AAPL / sigma2_AAPL) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w2 <- (mu_NLY / sigma2_NLY) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w3 <- (mu_XOM / sigma2_XOM) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$meanForecast
sigma2_AAPL_i <- (predict(model_AAPL, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$meanForecast
sigma2_NLY_i <- (predict(model_NLY, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$meanForecast
sigma2_XOM_i <- (predict(model_XOM, n.ahead = 1, n.start = i)$standardDeviation)^2
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
data=readEViews("data/Tarea1.wf1",time.stamp = FALSE)
data$DATE = NULL
# Obtener los rendimientos diarios de los stocks
ret_AAPL <- diff(log(data$AAPL))
ret_NLY <- diff(log(data$NLY))
ret_XOM <- diff(log(data$XOM))
# Ajustar los modelos GARCH a los rendimientos de cada stock
model_AAPL <- garchFit(formula = ~garch(1, 1), data = ret_AAPL, cond.dist = "QMLE")
model_NLY <- garchFit(formula = ~garch(1, 1), data = ret_NLY, cond.dist = "QMLE")
model_XOM <- garchFit(formula = ~garch(1, 1), data = ret_XOM, cond.dist = "QMLE")
# Obtener la media condicional y la varianza condicional de cada stock
mu_AAPL <- predict(model_AAPL, n.ahead = 1)$meanForecast
sigma2_AAPL <- (predict(model_AAPL, n.ahead = 1)$standardDeviation)^2
mu_NLY <- predict(model_NLY, n.ahead = 1)$meanForecast
sigma2_NLY <- (predict(model_NLY, n.ahead = 1)$standardDeviation)^2
mu_XOM <- predict(model_XOM, n.ahead = 1)$meanForecast
sigma2_XOM <- (predict(model_XOM, n.ahead = 1)$standardDeviation)^2
# Calcular las ponderaciones óptimas
w1 <- (mu_AAPL / sigma2_AAPL) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w2 <- (mu_NLY / sigma2_NLY) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
w3 <- (mu_XOM / sigma2_XOM) / ((mu_AAPL^2 / sigma2_AAPL) + (mu_NLY^2 / sigma2_NLY) + (mu_XOM^2 / sigma2_XOM))
# Calcular las ponderaciones óptimas en función del tiempo
n <- nrow(data)  # Número total de observaciones
weights <- matrix(NA, nrow = n, ncol = 3)
for (i in 1:n) {
# Obtener la media condicional y la varianza condicional en el momento i
mu_AAPL_i <- predict(model_AAPL, n.ahead = 1, n.start = i)$meanForecast
sigma2_AAPL_i <- (predict(model_AAPL, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_NLY_i <- predict(model_NLY, n.ahead = 1, n.start = i)$meanForecast
sigma2_NLY_i <- (predict(model_NLY, n.ahead = 1, n.start = i)$standardDeviation)^2
mu_XOM_i <- predict(model_XOM, n.ahead = 1, n.start = i)$meanForecast
sigma2_XOM_i <- (predict(model_XOM, n.ahead = 1, n.start = i)$standardDeviation)^2
# Calcular las ponderaciones óptimas en el momento i
weights[i, 1] <- (mu_AAPL_i / sigma2_AAPL_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 2] <- (mu_NLY_i / sigma2_NLY_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
weights[i, 3] <- (mu_XOM_i / sigma2_XOM_i) / ((mu_AAPL_i^2 / sigma2_AAPL_i) + (mu_NLY_i^2 / sigma2_NLY_i) + (mu_XOM_i^2 / sigma2_XOM_i))
}
# Graficar la evolución temporal de las ponderaciones óptimas
plot(data$Date, weights[, 1], type = "l", xlab = "Fecha", ylab = "Ponderación", col = "blue", ylim = c(0, 1))
# Paso 3: Calcular los rendimientos diarios
returns <- diff(log(df))
# Paso 4: Definir la función para estimar la media y varianza condicional utilizando modelos GARCH
garch_estimation <- function(returns) {
spec <- ugarchspec(mean.model = list(armaOrder = c(0, 0)), variance.model = list(model = "sGARCH"))
fit <- ugarchfit(spec, returns)
forecast <- ugarchforecast(fit, n.ahead = 1)
mu <- forecast@forecast$seriesFor[1]
sigma <- forecast@forecast$sigmaFor[1]
return(list(mu = mu, sigma = sigma))
}
# Paso 5: Calcular la media y varianza condicional para cada período de tiempo y obtener las ponderaciones óptimas
n <- nrow(returns)
weights <- matrix(0, n, length(symbols))
data=readEViews("data/Tarea2.wf1",time.stamp = FALSE)
data$DATE = NULL
df=readEViews("data/Tarea2.wf1",time.stamp = FALSE)
df$DATE = NULL
# Paso 3: Calcular los rendimientos diarios
returns <- diff(log(df))
