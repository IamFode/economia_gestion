( variance.est.1 <- var(theta.est.1) )
( mse.est.1 <- mean((theta.est.1-theta)^2) )
( bias.est.2 <- mean(theta.est.2-theta) )
( variance.est.2 <- var(theta.est.2) )
( mse.est.2 <- mean((theta.est.2-theta)^2) )
# all values in a row:
round(c(bias.est.1,variance.est.1,mse.est.1,bias.est.2,variance.est.2,mse.est.2),4)
# Eficiencia relativa entre los errores cuadráticos medios de dos estimadores
( mse.est.2=mean((theta.est.2-theta)^2) ) / ( mse.est.1=mean((theta.est.1-theta)^2) )
par(mfrow=c(1,2))
#estimador de momentos
hist(theta.est.1,freq=F,xlab="moments",main=paste("n=",n,sep=""))
abline(v=theta,lty=2,col="red",lwd=2)
#Estimador de maximasimilitud
hist(theta.est.2,freq=F,xlab="MLE",main=paste("n=",n,sep=""))
abline(v=theta,lty=2,col="red",lwd=2)
############################## Ejercicio 1 #####################################
x =  rnorm(20,mean=7,sd=2)
mean(x)
median(x)
M = 10000
mu.est <- numeric(M)
median.est <- numeric(M)
mu = 7
sigma = 1
n = 25
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
mu.est[i] <- mean(x)
median.est[i] <- median(x)
}
( bias.est=mean(mu.est-mu) )
( variance.est=var(mu.est) )
( mse.est=mean((mu.est-mu)^2) )
( bias.est=mean(median.est-mu) )
( variance.est=var(median.est) )
( mse.est=mean((median.est-mu)^2) )
# MSE_mean / MSE_median
( mse.est=mean((mu.est-mu)^2) ) / ( mse.est=mean((median.est-mu)^2) )
hist(x)
round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
############################## Ejercicio 1 #####################################
x =  rnorm(20,mean=7,sd=2)
mean(x)
median(x)
M = 10000
mu.est <- numeric(M)
median.est <- numeric(M)
mu = 7
sigma = 1
n = 25
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
mu.est[i] <- mean(x)
median.est[i] <- median(x)
}
( bias.est=mean(mu.est-mu) )
( variance.est=var(mu.est) )
( mse.est=mean((mu.est-mu)^2) )
( bias.est_m=mean(median.est-mu) )
( variance.est_m=var(median.est) )
( mse.est_m=mean((median.est-mu)^2) )
round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
"Para cada tamaño de muestra, calcule la eficiencia relativa entre los estimadores.
¿Qué concluirías? ¿Qué estimador tiene un mejor desempeño práctico?"
" Respuesta. El mejor estimador será para mean ya que su error cuadratico medio
es menor"
# MSE_mean / MSE_median
( mse.est=mean((mu.est-mu)^2) ) / ( mse.est=mean((median.est-mu)^2) )
"Para cada tamaño de muestra, calcule la eficiencia relativa entre los estimadores.
¿Qué concluirías? ¿Qué estimador tiene un mejor desempeño práctico?"
'''
Para cada tamaño de muestra, calcule la eficiencia relativa entre los estimadores.
¿Qué concluirías? ¿Qué estimador tiene un mejor desempeño práctico?
'''
'''
Para cada tamaño de muestra, calcule la eficiencia relativa entre los estimadores.
¿Qué concluirías? ¿Qué estimador tiene un mejor desempeño práctico?
'''
'''
Para cada tamaño de muestra, calcule la eficiencia relativa entre los estimadores.
¿Qué concluirías? ¿Qué estimador tiene un mejor desempeño práctico?
'''
"
El método de momentos se comporta mejor en temas de sesgo y el método de monte
carlo se comporta mejor en términos de varianza.
El método de monte Carlo es mejor porque tiene menor error cuatrático medio.
Mientas más datos entonces el método monte carlo es mejor que el método de momentos
"
round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
c25 <- round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
M = 10000
mu.est <- numeric(M)
median.est <- numeric(M)
mu = 7
sigma = 1
n = 50
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
mu.est[i] <- mean(x)
median.est[i] <- median(x)
}
( bias.est=mean(mu.est-mu) )
( variance.est=var(mu.est) )
( mse.est=mean((mu.est-mu)^2) )
( bias.est_m=mean(median.est-mu) )
( variance.est_m=var(median.est) )
( mse.est_m=mean((median.est-mu)^2) )
c50 <- round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
M = 10000
mu.est <- numeric(M)
median.est <- numeric(M)
mu = 7
sigma = 1
n = 100
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
mu.est[i] <- mean(x)
median.est[i] <- median(x)
}
( bias.est=mean(mu.est-mu) )
( variance.est=var(mu.est) )
( mse.est=mean((mu.est-mu)^2) )
( bias.est_m=mean(median.est-mu) )
( variance.est_m=var(median.est) )
( mse.est_m=mean((median.est-mu)^2) )
c100 <- round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
M = 10000
mu.est <- numeric(M)
median.est <- numeric(M)
mu = 7
sigma = 1
n = 200
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
mu.est[i] <- mean(x)
median.est[i] <- median(x)
}
( bias.est=mean(mu.est-mu) )
( variance.est=var(mu.est) )
( mse.est=mean((mu.est-mu)^2) )
( bias.est_m=mean(median.est-mu) )
( variance.est_m=var(median.est) )
( mse.est_m=mean((median.est-mu)^2) )
c200 <- round(c(bias.est,variance.est,mse.est,bias.est_m,variance.est_m,mse.est_m),4)
round(c(c25,\n c50,\n c100, \n c200))
round(c(c25, c50, c100,  c200))
round(c(c25, c50, c100,  c200),5)
c25
c50
c100
c200
var <- 2
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 2
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 2
n <- 100
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
hist(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 2
n <- 100
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
hist(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 2
n <- 100
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)**2
}
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
x <- rnorm(n,mean=mu,sd=sigma)
x
x
x
x
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 2
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
( bias.est <- mean(var.est-var) )
x
mean(x)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 3
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(x)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 4
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(x)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 5
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(x)
x<-rnorm(n,mean=mu,sd=sigma)
x
var(x)
var.est
mean(var.est)
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 5
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 1
mu <- 5
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 1
mu <- 0
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 1
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 2
mu <- 10
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 10
mu <- 10
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
################################ Ejercicio 2 ###################################
# Parametros de interes varianza
M <- 10000
var.est <- numeric(M)
var <- 1
mu <- 0
n <- 10
for (i in 1:M){
x <- rnorm(n,mean=mu,sd=sigma)
var.est[i] <- var(x)
}
mean(var.est)
( bias.est <- mean(var.est-var) )
( variance.est <- var(var.est) )
( mse.est <- mean((var.est-var)^2) )
hist(var.est)
# Fix the number of Monte Carlo simulations M
M=10000
# Create a vector that will save the values of the estimator
theta.est.1 <- numeric(M)
theta.est.2 <- numeric(M)
theta.est.3 <- numeric(M) # mejor estimador
# Fix the true value of the parameter
theta <- 2
# Fix the sample size (consider sereral values)
n <- 25
# Repeat in a loop M times
for (i in 1:M){
# Step 1.: simulate a sample from a distribution with mean mu
x=runif(n,min=0,max=theta)
# Step 2.: evaluate the estimator in the simulated sample
theta.est.1[i] <- 2*mean(x)   # method of moments estimator
theta.est.2[i] <- max(x)   # maximum likelihood estimator
theta.est.3[i] <- max(x)*(n+1)/n   # maximum likelihood estimator
}
# Bias, variance and MSE:
( bias.est.1 <- mean(theta.est.1-theta) )
( variance.est.1 <- var(theta.est.1) )
( mse.est.1 <- mean((theta.est.1-theta)^2) )
( bias.est.2 <- mean(theta.est.2-theta) )
( variance.est.2 <- var(theta.est.2) )
( mse.est.2 <- mean((theta.est.2-theta)^2) )
#mejor estimador (n-1)/n
( bias.est.3 <- mean(theta.est.3-theta) )
( variance.est.3 <- var(theta.est.3) )
( mse.est.3 <- mean((theta.est.3-theta)^2) )
# Fix the number of Monte Carlo simulations M
M=10000
# Create a vector that will save the values of the estimator
tau.est.1=numeric(M)
tau.est.2=numeric(M)
# Fix the sample size (consider sereral values)
n=50
# Repeat in a loop M times
for (i in 1:M){
# Step 1.: simulate a sample from a distribution with mean mu
# x=rnorm(n); tau=qnorm(0.95)
# x=rt(n,df=5); tau=qt(0.95,df=5)
x=rexp(n,rate=0.5); tau=qexp(0.95,rate=0.5)
# Step 2.: evaluate the estimator in the simulated sample
tau.est.1[i]=quantile(x,0.95)   # non-parametric estimator
tau.est.2[i]=mean(x) + qnorm(0.95)*sd(x)  # parametric estimator
}
# Bias, variance and MSE of the estimators:
( bias.est.1=mean(tau.est.1-tau) )
( variance.est.1=var(tau.est.1) )
( mse.est.1=mean((tau.est.1-tau)^2) )
( bias.est.2=mean(tau.est.2-tau) )
( variance.est.2=var(tau.est.2) )
( mse.est.2=mean((tau.est.2-tau)^2) )
# all values in a row:
round(c(bias.est.1,variance.est.1,mse.est.1,bias.est.2,variance.est.2,mse.est.2),4)
par(mfrow=c(1,2))
hist(tau.est.1,freq=F,xlab="non-parametric estimator",main=paste("n=",n,sep=""))
abline(v=tau,lty=2,col="red",lwd=2)
hist(tau.est.2,freq=F,xlab="parametric estimator",main=paste("n=",n,sep=""))
abline(v=tau,lty=2,col="red",lwd=2)
# Fix the number of Monte Carlo simulations M
M=10000
# Create a vector that will save the values of the estimator
tau.est.1=numeric(M)
tau.est.2=numeric(M)
# Fix the sample size (consider sereral values)
n=400
# Repeat in a loop M times
for (i in 1:M){
# Step 1.: simulate a sample from a distribution with mean mu
# x=rnorm(n); tau=qnorm(0.95)
# x=rt(n,df=5); tau=qt(0.95,df=5)
x=rexp(n,rate=0.5); tau=qexp(0.95,rate=0.5)
# Step 2.: evaluate the estimator in the simulated sample
tau.est.1[i]=quantile(x,0.95)   # non-parametric estimator
tau.est.2[i]=mean(x) + qnorm(0.95)*sd(x)  # parametric estimator
}
# Bias, variance and MSE of the estimators:
( bias.est.1=mean(tau.est.1-tau) )
( variance.est.1=var(tau.est.1) )
( mse.est.1=mean((tau.est.1-tau)^2) )
( bias.est.2=mean(tau.est.2-tau) )
( variance.est.2=var(tau.est.2) )
( mse.est.2=mean((tau.est.2-tau)^2) )
# all values in a row:
round(c(bias.est.1,variance.est.1,mse.est.1,bias.est.2,variance.est.2,mse.est.2),4)
# Fix the number of Monte Carlo simulations M
M=10000
# Create a vector that will save the values of the estimator
tau.est.1=numeric(M)
tau.est.2=numeric(M)
# Fix the sample size (consider sereral values)
n=1000
# Repeat in a loop M times
for (i in 1:M){
# Step 1.: simulate a sample from a distribution with mean mu
# x=rnorm(n); tau=qnorm(0.95)
# x=rt(n,df=5); tau=qt(0.95,df=5)
x=rexp(n,rate=0.5); tau=qexp(0.95,rate=0.5)
# Step 2.: evaluate the estimator in the simulated sample
tau.est.1[i]=quantile(x,0.95)   # non-parametric estimator
tau.est.2[i]=mean(x) + qnorm(0.95)*sd(x)  # parametric estimator
}
# Bias, variance and MSE of the estimators:
( bias.est.1=mean(tau.est.1-tau) )
( variance.est.1=var(tau.est.1) )
( mse.est.1=mean((tau.est.1-tau)^2) )
( bias.est.2=mean(tau.est.2-tau) )
( variance.est.2=var(tau.est.2) )
( mse.est.2=mean((tau.est.2-tau)^2) )
# all values in a row:
round(c(bias.est.1,variance.est.1,mse.est.1,bias.est.2,variance.est.2,mse.est.2),4)
par(mfrow=c(1,2))
hist(tau.est.1,freq=F,xlab="non-parametric estimator",main=paste("n=",n,sep=""))
abline(v=tau,lty=2,col="red",lwd=2)
hist(tau.est.2,freq=F,xlab="parametric estimator",main=paste("n=",n,sep=""))
abline(v=tau,lty=2,col="red",lwd=2)
# Fix the number of Monte Carlo simulations M
M=10000
# Create a vector that will save the values of the estimator
tau.est.1=numeric(M)
tau.est.2=numeric(M)
# Fix the sample size (consider sereral values)
n=400
# Repeat in a loop M times
for (i in 1:M){
# Step 1.: simulate a sample from a distribution with mean mu
# x=rnorm(n); tau=qnorm(0.95)
# x=rt(n,df=5); tau=qt(0.95,df=5)
x=rexp(n,rate=0.5); tau=qexp(0.95,rate=0.5)
# Step 2.: evaluate the estimator in the simulated sample
tau.est.1[i]=quantile(x,0.95)   # non-parametric estimator
tau.est.2[i]=mean(x) + qnorm(0.95)*sd(x)  # parametric estimator
}
# Bias, variance and MSE of the estimators:
( bias.est.1=mean(tau.est.1-tau) )
( variance.est.1=var(tau.est.1) )
( mse.est.1=mean((tau.est.1-tau)^2) )
( bias.est.2=mean(tau.est.2-tau) )
( variance.est.2=var(tau.est.2) )
( mse.est.2=mean((tau.est.2-tau)^2) )
# all values in a row:
round(c(bias.est.1,variance.est.1,mse.est.1,bias.est.2,variance.est.2,mse.est.2),4)
par(mfrow=c(1,2))
